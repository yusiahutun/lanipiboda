<!doctype html><html lang=en><head><meta charset=utf-8><meta name=HandheldFriendly content="True"><meta name=MobileOptimized content="320"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=referrer content="no-referrer"><meta name=description content="You can install Stable Diffusion locally on your PC, but the typical process involves a lot of work with the command line to install and use. Fortunately for us, the Stable Diffusion community has solved that problem. Here's how to install a version of Stable Diffusion that runs locally with a graphical user interface!"><meta name=robots content="index,follow,noarchive"><link href="https://fonts.googleapis.com/css?family=Open+Sans:400|Old+Standard+TT:400&display=swap" rel=stylesheet media=print type=text/css onload='this.media="all"'><title>How to Run Stable Diffusion Locally With a GUI on Windows</title><link rel=canonical href=./how-to-run-stable-diffusion-locally-with-a-gui-on-windows.html><style>*{border:0;font:inherit;font-size:100%;vertical-align:baseline;margin:0;padding:0;color:#000;text-decoration-skip:ink}body{font-family:open sans,myriad pro,Myriad,sans-serif;font-size:17px;line-height:160%;color:#1d1313;max-width:700px;margin:auto}p{margin:20px 0}a img{border:none}img{margin:10px auto;max-width:100%;display:block}.left-justify{float:left}.right-justify{float:right}pre,code{font:12px Consolas,liberation mono,Menlo,Courier,monospace;background-color:#f7f7f7}code{font-size:12px;padding:4px}pre{margin-top:0;margin-bottom:16px;word-wrap:normal;padding:16px;overflow:auto;font-size:85%;line-height:1.45}pre>code{padding:0;margin:0;font-size:100%;word-break:normal;white-space:pre;background:0 0;border:0}pre code{display:inline;padding:0;margin:0;overflow:visible;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}pre code::before,pre code::after{content:normal}em,q,em,dfn{font-style:italic}.sans,html .gist .gist-file .gist-meta{font-family:open sans,myriad pro,Myriad,sans-serif}.mono,pre,code,tt,p code,li code{font-family:Menlo,Monaco,andale mono,lucida console,courier new,monospace}.heading,.serif,h1,h2,h3{font-family:old standard tt,serif}strong{font-weight:600}q:before{content:"\201C"}q:after{content:"\201D"}del,s{text-decoration:line-through}blockquote{font-family:old standard tt,serif;text-align:center;padding:50px}blockquote p{display:inline-block;font-style:italic}blockquote:before,blockquote:after{font-family:old standard tt,serif;content:'\201C';font-size:35px;color:#403c3b}blockquote:after{content:'\201D'}hr{width:40%;height:1px;background:#403c3b;margin:25px auto}h1{font-size:35px}h2{font-size:28px}h3{font-size:22px;margin-top:18px}h1 a,h2 a,h3 a{text-decoration:none}h1,h2{margin-top:28px}#sub-header,.date{color:#403c3b;font-size:13px}#sub-header{margin:0 4px}#nav h1 a{font-size:35px;color:#1d1313;line-height:120%}.posts_listing a,#nav a{text-decoration:none}li{margin-left:20px}ul li{margin-left:5px}ul li{list-style-type:none}ul li:before{content:"\00BB \0020"}#nav ul li:before,.posts_listing li:before{content:'';margin-right:0}#content{text-align:left;width:100%;font-size:15px;padding:60px 0 80px}#content h1,#content h2{margin-bottom:5px}#content h2{font-size:25px}#content .entry-content{margin-top:15px}#content .date{margin-left:3px}#content h1{font-size:30px}.highlight{margin:10px 0}.posts_listing{margin:0 0 50px}.posts_listing li{margin:0 0 25px 15px}.posts_listing li a:hover,#nav a:hover{text-decoration:underline}#nav{text-align:center;position:static;margin-top:60px}#nav ul{display:table;margin:8px auto 0}#nav li{list-style-type:none;display:table-cell;font-size:15px;padding:0 20px}#links{display:flex;justify-content:space-between;margin:50px 0 0}#links :nth-child(1){margin-right:.5em}#links :nth-child(2){margin-left:.5em}#not-found{text-align:center}#not-found a{font-family:old standard tt,serif;font-size:200px;text-decoration:none;display:inline-block;padding-top:225px}@media(max-width:750px){body{padding-left:20px;padding-right:20px}#nav h1 a{font-size:28px}#nav li{font-size:13px;padding:0 15px}#content{margin-top:0;padding-top:50px;font-size:14px}#content h1{font-size:25px}#content h2{font-size:22px}.posts_listing li div{font-size:12px}}@media(max-width:400px){body{padding-left:20px;padding-right:20px}#nav h1 a{font-size:22px}#nav li{font-size:12px;padding:0 10px}#content{margin-top:0;padding-top:20px;font-size:12px}#content h1{font-size:20px}#content h2{font-size:18px}.posts_listing li div{font-size:12px}}@media(prefers-color-scheme:dark){*,#nav h1 a{color:#fdfdfd}body{background:#121212}pre,code{background-color:#262626}#sub-header,.date{color:#bababa}hr{background:#ebebeb}}</style></head><body><section id=nav><h1><a href=./index.html>WinkBlog</a></h1><ul><li><a href=./index.xml>Rss</a></li><li><a href=./sitemap.xml>Sitemap</a></li></ul></section><section id=content><h1>How to Run Stable Diffusion Locally With a GUI on Windows</h1><div id=sub-header>October 2024 · 15 minute read</div><div class=entry-content><h3>Quick Links</h3><ul class=table-content-level-1><li><a href=#>What Is Stable Diffusion?</a></li></ul><ul class=table-content-level-1><li><a href=#>What Do You Need to Run This Version of Stable Diffusion?</a></li></ul><ul class=table-content-level-1><li><a href=#>How to Install Stable Diffusion with a GUI</a></li></ul><ul class=table-content-level-1><li><a href=#>How to Generate Images Using Stable Diffusion with AUTOMATIC1111's WebUI</a></li></ul><ul class=table-content-level-1><li><a href=#>How to Mask Images You Create to Inpaint</a></li></ul><ul class=table-content-level-1><li><a href=#>How to Use Stable Diffusion with ComfyUI</a></li></ul><ul class=table-content-level-1><li><a href=#>How to Fix the "CUDA Out Of Memory" Error in AUTOMATIC1111's WebUI</a></li></ul><p>You can <a href=#>install Stable Diffusion locally on your PC</a>, but the typical process involves a lot of work with the command line to install and use. Fortunately for us, the Stable Diffusion community has solved that problem. Here's how to install a version of Stable Diffusion that runs locally with a graphical user interface!</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><h2 id=what-is-stable-diffusion>What Is Stable Diffusion?</h2><p>Stable Diffusion is an AI model that can generate images from text prompts, or modify existing images with a text prompt, much like <a href=#>MidJourney</a> or <a href=#>DALL-E 2</a>. It was first released in August 2022 by <a href=#>Stability.ai.</a> It understands thousands of different words and can be used to create almost any image your imagination can conjure up in almost any style.</p><p>There are two critical differences that set Stable Diffusion apart from most of the other popular AI art generators, though:</p><ul><li>It can be <a href=#>run locally on your PC</a></li><li>It is an open-source project</li></ul><p><span class=related-single>Related: <a href=#>Stable Diffusion Brings Local AI Art Generation to Your PC</a></span></p><p>The last point is really the important issue here. Traditionally, <a href=#>Stable Diffusion is installed and run via a command-line interface</a>. It works, but it can be clunky, unintuitive, and it is a significant barrier to entry for people that would otherwise be interested. But, since it is an open source project, the community quickly created multiple user interfaces for it and began adding their own augmentations, including optimizations to minimize video ram (<a href=#>VRAM</a>) usage and build in upscaling and masking.</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><h2 id=what-do-you-need-to-run-this-version-of-stable-diffusion>What Do You Need to Run This Version of Stable Diffusion?</h2><p>We're going to cover two different forks (offshoots) of Stable Diffusion of <a href=#>the main repository (repo) created and maintained by Stability.ai</a>. They both have a <a href=#>graphical user interface (GUI)</a> — making them easier to use than the regular Stable Diffusion, which only has a <a href=#>command-line interface</a> — and an installer that'll handle most of the setup automatically. They both provide the same basic functionality, but the user experience is quite different. AUTOMATIC1111's WebUI is very intuitive, and the easiest to learn and use, but ComfyUI offers an interesting and powerful node-based user interface that will appeal to power users and anyone that wants to chain multiple models together.</p><p>As always, be careful with third-party forks of software that you find on GitHub. We've been using these for a while now with no issues, and so have thousands of others, so we're inclined to say it is safe. Fortunately, the code and changes here are small compared to some forks of open-source projects.</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><p>These forks also contains various optimizations that should allow it to run on PCs with less RAM, built-in upscaling and facial capabilities using GFPGAN, ESRGAN, RealESRGAN, and CodeFormer, and masking. Masking is a huge deal — it allows you to selectively apply the AI image generation to certain parts of the image without distorting other parts, a process typically called inpainting.</p><ul><li>A minimum of 10 gigabytes free on your hard drive<ul><li>You can reuse the same Python environment and checkpoints to save on space if you want to use both ComfyUI and AUTOMATIC1111's WebUI.</li><li>You may also simply install them separately, which is much easier.</li></ul></li><li>An NVIDIA GPU with 6 GB of RAM (though you might be able to make 4 GB work)<ul><li>SDXL will require even more RAM to generate larger images.</li><li>You can make AMD GPUs work, but they require tinkering</li></ul></li><li>A PC running Windows 11, Windows 10, Windows 8.1, or Windows 8</li><li>One of:<ul><li><a href=# rel="noopener noreferrer">The WebUI GitHub Repo</a> by AUTOMATIC1111</li><li><a href=# rel="noopener noreferrer">ComfyUI</a></li></ul></li><li><a href=#>Python 3.10.6</a> (Use this version to ensure there aren't compatibility problems)</li><li><a href=# rel="noopener noreferrer">The Stable Diffusion Official Checkpoints</a> (Keep an eye out for new versions!)</li><li>Any <a href=#>additional models</a> you might want. You can use as many or few as you want.</li></ul><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><h2 id=how-to-install-stable-diffusion-with-a-gui>How to Install Stable Diffusion with a GUI</h2><p>The installation process has been streamlined significantly, but there are still a few steps you need to do manually before the installer can be used.</p><h3 id=install-python-first>Install Python First</h3><p>The first thing you should do is <a href=#>install the version of Python, 3.10.6</a>, recommended by the author of the repo. Head to that link, scroll towards the bottom of the page, and click "<a href=#>Windows Installer (64-Bit)</a>."</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2022/09/windows-installer-1.png><p>Click the executable you <a href=#>downloaded</a> and go through the prompts. If you already have Python installed (and you most certainly do), just click "Upgrade." Otherwise follow along with the recommended prompts.</p><p>Make certain that you add Python 3.10.6 to the PATH if you get an option for that.</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><h3 id=install-git-and-download-the-github-repo>Install Git and Download the GitHub Repo</h3><p>You need to <a href=#>download and install Git on Windows</a> before the Stable Diffusion installer can be run. Just download the <a href=#>64-bit Git executable</a>, run it, and use the recommended settings unless you have something specific in mind.</p><p><span class=related-single>Related: <a href=#>How to Install Git on Windows</a></span></p><p>Next, you need to download the files from the GitHub for either <a href=# rel="noopener noreferrer">AUTOMATIC1111's WebUI</a>, <a href=# rel="noopener noreferrer">ComfyUI</a>, or both.</p><p>If you're going with AUTOMATIC1111's WebUI, click the green "Code" button, then click "Download ZIP" at the bottom of the menu.</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2022/09/clcik-code-click-download-zip.png><p>If you want to take ComfyUI out for a spin, scroll down to the "<a href=# rel="noopener noreferrer">Installing</a>" section, and click "Direct Link to Download."</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong> <img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2023/08/direct.png><p>Open up the archive file in File Explorer or your preferred <a href=#>file archiving program</a>, and then extract the contents anywhere you want. Just keep in mind that folder is where you'll need to go to run Stable Diffusion. This example extracted them to the C:\ directory, but that isn't essential.</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2022/09/drag-and-drop.png><p>Make sure you don't accidentally drag "stable-diffusion-webui-master" or "ComfyUI_windows_portable" onto another folder rather than empty space — if you do, it'll drop into that folder, not the parent folder you intended.</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><h3 id=download-all-the-checkpoints>Download All The Checkpoints</h3><p>There are a few checkpoints you require for this to work. The first and most important are the <a href=#>Stable Diffusion Checkpoints</a>. At the time of writing, AUTOMATIC1111's WebUI will automatically fetch the version 1.5 checkpoints for you. If you want to use the SDXL checkpoints, you'll need to <a href=# rel="noopener noreferrer">download them manually</a>. ComfyUI doesn't fetch the checkpoints automatically. You may want to also <a href=# rel="noopener noreferrer">grab the refiner checkpoint</a>. It isn't strictly necessary, but it can improve the results you get from SDXL, and it is easy to flip on and off.</p><p>The checkpoints download is several gigabytes. Don't expect it to be done instantly.</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><p>Once the checkpoints are downloaded, you must place them in the correct folder. If you're following what we've done exactly, that path will be "C:\stable-diffusion-webui\models\Stable-diffusion" for AUTOMATIC1111's WebUI, or "C:\ComfyUI_windows_portable\ComfyUI\models\checkpoints" for ComfyUI.</p><p>Now you have options. You can add additional models (like <a href=#>ESRGAN, Loras</a>, etc) that add extra functions. Some simply increase upscaling quality, whereas others are designed to give better results for specific types of images, like anime, landscape photographs, realistic portaits, specific artists, or almost anything else you can imagine. Both ComfyUI and AUTOMATIC1111's WebUI create appropriately named folders for those additional models — just drag and drop, and you're good.</p><p>Now you just have to run the batch file for either ComfyUI or AUTOMATIC1111's WebUI. Open up the main AUTOMATIC1111's WebUI folder and double click "webui-user.bat" if you want to use that interface, or open up the ComfyUI folder and click "run_nvidia_gpu.bat" to run ComfyUI.</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><p>Expect the first time you run this to take at least a few minutes. It needs to download a bunch of stuff off the Internet. If it appears to hang for an unreasonably long time at one step, just try selecting the console window and hitting the Enter key.</p><p>They'll both look something like that.</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2022/09/looks-like-this.png><p>When it is done, the console will display:</p><pre>Running on local URL: http://<a href=#>127.0.0.1</a>:7860 To create a public link, set `share=True` in `launch()`</pre><p><span class=related-single>Related: <a href=#>What Is the 127.0.0.1 IP Address, and How Do You Use It?</a></span></p><p>ComfyUI will run on the same IP address, since it is a locally hosted web interface, but it runs on the 8188 port instead of 7860.</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><h2 id=how-to-generate-images-using-stable-diffusion-with-automatic1111-39-s-webui>How to Generate Images Using Stable Diffusion with AUTOMATIC1111's WebUI</h2><p>Alright, you've installed the WebUI variant of Stable Diffusion, and your console let you know that it is "running on local URL: http://127.0.0.1:7860."</p><p>What exactly does that mean, what is happening? <a href=#>127.0.0.1 is the localhost address</a> — the IP address your computer gives itself. This version of Stable Diffusion creates a server on your local PC that is accessible via its own IP address, but only if you connect through the correct <a href=#>port</a> : 7860.</p><p>Open up your browser, enter "127.0.0.1:7860" or "localhost:7860" into the address bar, and hit Enter. You'll see this on the txt2img tab:</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2022/09/SD_MAIN_SCREEN_UPDATE.png><p>If you've used Stable Diffusion before, these settings will be familiar to you, but here is a brief overview of what the most important options mean:</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><ul><li><strong>Prompt:</strong> The description of what you'd like to create.</li><li><strong>Painter's Pallete Button: </strong>Applies a random artistic style to your prompt.</li><li><strong>Sampling Steps: </strong>The number of times the image will be refined before you receive an output. More is generally better, but there are diminishing returns.</li><li><strong>Sampling Method: </strong>The underlying math that governs how sampling is handled. You can use any of these, but euler_a and PLMS seem to be the most popular options. You can read more about <a href=#>PLMS in this paper.</a></li><li><strong>Restore Faces:</strong> Uses GFPGAN to try to fix uncanny or distorted faces.</li><li><strong>Batch Count: </strong>The number of images to be generated.</li><li><strong>Batch Size: </strong>The number of "batches". Keep this at 1 unless you have an enormous amount of VRAM.</li><li><strong>CFG Scale: </strong>How carefully Stable Diffusion will follow the prompt you give it. Larger numbers mean it follows it very carefully, whereas lower numbers give it more creative freedom.</li><li><strong>Width: </strong>The width of the image you want to generate.</li><li><strong>Height: </strong>The width of the image you want to generate.</li><li><strong>Seed: </strong>The number that provides an initial input for a random-number generator. Leave it at -1 to randomly generate a new seed.</li></ul><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><p>Let's generate five images based on the prompt: "a highland cow in a magical forest, 35mm film photography, sharp" and see what we get using the Euler a sampler, 40 sampling steps, and a CFG scale of 5.</p><p>You can always hit the "Interrupt" button to stop generation if your job is taking too long.</p><p>The output window will look like this:</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2023/08/cows-correctly-sized-lol.png><p>Your images will be different.</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><p>The bottom-left image is the one we'll use to try out for masking a bit later. There isn't really a reason for this specific choice other than personal preference. Grab any image that you like.</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2023/08/cute-cow.png><p>Select it, and then click "Send to Inpaint."</p><h2 id=how-to-mask-images-you-create-to-inpaint>How to Mask Images You Create to Inpaint</h2><p>Inpainting is a fantastic feature. Normally Stable Diffusion is used to create entire images from a prompt, but inpainting allows you selectively generate (or regenerate) parts of the image. There are two critical options here: inpaint masked, inpaint not masked.</p><p>Inpaint masked will use the prompt to generate imagery within the area you highlight, whereas inpaint not masked will do the exact opposite — only the area you mask will be preserved.</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><p>We'll cover a bit about Inpaint masked first. Drag your mouse around on the image holding left click and you'll notice a white layer appearing over top of your image. Draw out the shape of the area you want to be replaced, and be sure to fill it in entirely. You aren't circling a region, you're masking in the entire region.</p><p>If you're just adding something to an existing picture, it can be helpful to try to make the masked region line up with the approximate shape you're trying to create. Masking a triangular shape when you want a circle, for example, is counter-productive.</p><p>Let's take our highland cow example and give him a chef's hat. Mask out a region in approximately the shape of a Chef's hat, and make sure to set "Batch Size" to more than 1. You'll probably need multiple to get an ideal(ish) result.</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><p>Additionally, you should select "Latent Noise" rather than "Fill," "Original," or "Latent Nothing." It tends to produce the best results when you want to generate a completely new object in a scene.</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2023/08/cow-with-chef-s-hat.png> Prompt: "a highland cow wearing a chef's hat in a magical forest, 35mm film photography, sharp"<br>Mask Blur: 10<br>Masked Content: Latent Noise<br>Inpaint Area: Whole Picture<br>Sampling Method: Euler A<br>Sampling Steps: 30<br>CFG Scale: 5<p>Alright — maybe a chef's hat isn't the right pick for your highland cow. Your highland cow is more into the early-20th century vibes, so let's give him a bowler hat.</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2023/08/cow-in-bowler-hat.png> Prompt: "a highland cow wearing a bowler hat in a magical forest, 35mm film photography, sharp"<br>Mask Blur: 10<br>Masked Content: Latent Noise<br>Inpaint Area: Whole Picture<br>Sampling Method: Euler A<br>Sampling Steps: 30<br>CFG Scale: 5<p>How positively dapper.</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><p>Of course, you can also do the exact opposite with Inpaint Not Masked. It is conceptually similar, except the regions you define are reversed. Instead of marking out the region you want to change, you mark out the regions you want to be preserved. It is often useful when you want to move a small object onto a different background.</p><h2 id=how-to-use-stable-diffusion-with-comfyui>How to Use Stable Diffusion with ComfyUI</h2><p>ComfyUI is very different from AUTOMATIC1111's WebUI, but arguably more useful if you want to really customize your results. ComfyUI runs on nodes. If you're not familiar with how a node-based system works, here is an analogy that might be helpful.</p><p>Imagine that ComfyUI is a factory that produces an image. Within the factory there are a variety of machines that do various things to create a complete image, just like you might have multiple machines in a factory that produces cars. In the case of ComfyUI and Stable Diffusion, you have a few different "machines," or nodes. It looks like this:</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong> <img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2023/08/comfyui.png><p>It looks worse than it really is. Here's what each node does:</p><ul><li><strong>Load Checkpoint: </strong>Loads the trained model.</li><li><strong>Clip Text Encode: </strong>Where you enter a prompt. There are two because we have both a positive prompt, which tells Stable Diffusion what you want, and a negative prompt, which tells it what to avoid.</li><li><strong>Empty Latent Image:</strong> Creates a blank (noisey) image.</li><li><strong>KSampler:</strong> The node that containers the sampler. The sampler is the part of the program that converts random noise into recognizeable "stuff".</li><li><strong>VAE Decode: </strong>Creates the final image.</li><li><strong>Save Image:</strong> Writes the image to your hard drive.</li></ul><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><p>Each node has various attachment points that tell you what you need to "plug in" to each point, much like conveyor belts connecting different machines in a factory. So if you wanted the prompt: "a highland cow in a magical forest, 35mm film photography, sharp" you'd enter it in the box attached to the "positive" position on the sampler node.</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2023/08/node-setup.png><p>We disconnected the latent image and model nodes to clear up some clutter for the screenshot, but they <strong>must</strong> be connected for Stable Diffusion to function.</p><p>Then you need to pick the settings you want the sampler to use. You can get wildly different results here depending on what you select.</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><ul><li><strong>Seed:</strong> A random number used to generate the original noise in the image.</li><li><strong>CFG:</strong> How strongly Stable Diffusion will adhere to the prompt. The higher the value, the more carefully Stable Diffusion will follow the prompt.</li><li><strong>Steps:</strong> How many times the sampler will sample the noise to generate an image.</li><li><strong>Sampler_name:</strong> The sampler that you use to sample the noise. These usually produce different results, so test out multiple.</li><li><strong>Denoise:</strong> Relevant to inpainting and img2img. Relates to how much your output image resembles your input image. The higher the value, the more dissimilar they will be.</li></ul><p>Adjust the height and width values "Empty Latent Image" node to change the size of the output image. Start with 512x512 if your GPU doesn't have much memory. If you have 12 GB of VRAM (or more) you should be able to produce 1024x1024 images without any issue, however. You can also change the batch size to produce more than one variant of each prompt when you initiate image generation.</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong> <img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2023/08/2023-08-01_18h58_27.png><p>Now you're done. Click "Queue Prompt" to initiate image generation. You will see each node light up while it is active.</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2023/08/queue-prompt.png><p>Here is one of the images we got:</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2023/08/comfyui_00003_.png> <strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><p>ComfyUI is powerful, and extremely flexible. If you want to perform additional operations on an image, just right-click and start adding nodes.</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2023/08/2023-08-01_19h11_54.png><p>You can add as many model and modification nodes as you want, but keep in mind that every step in the process, every node you add, will increase computational time. The Stable Diffusion community has created a huge number of pre-built node arrangements (called workflows, usually) that allow you to fine-tune your results. We've tested a few and found they can often significantly improve your results. As always, be cautious downloading and using community resources — the Stable Diffusion community is fairly safe, but you can never be too careful.</p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><h2 id=how-to-fix-the-quot-cuda-out-of-memory-quot-error-in-automatic1111-39-s-webui>How to Fix the "CUDA Out Of Memory" Error in AUTOMATIC1111's WebUI</h2><p>The bigger the image you make, the more video memory is required. The first thing you should try is generating smaller images. Stable Diffusion produces good — albeit very different — images at 256x256.</p><p>If you're itching to make larger images on a computer that doesn't have issues with 512x512 images, or you're running into various "Out of Memory" errors, there are some changes to the configuration that should help.</p><p><a href=#>Open up "webui-user.bat" in Notepad</a>, or any other plain text editor you want. Just right-click "webui-user.bat," click "Edit," and then select Notepad. Identify the line that reads <code>set COMMANDLINE_ARGS=</code>. That is where you're going to place the commands to optimize how Stable Diffusion runs.</p><p><span class=related-single>Related: <a href=#>How to Write a Batch Script on Windows</a></span></p><strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><p>If you just want to make huge pictures, or you're running out of RAM on a GTX 10XX series GPU, try out <code>--opt-split-attention</code> first. It'll look like this:</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2022/09/notepad.png><p>Then click File > Save. Alternatively, you can hit Ctrl+S on your keyboard.</p><p>If you're still getting memory errors, try adding <code>--medvram</code> to the list of command line arguments (COMMANDLINE_ARGS).</p><img style=margin:auto;display:block;text-align:center;max-width:100%;height:auto src=https://cdn.statically.io/img/static1.howtogeekimages.com/wordpress/wp-content/uploads/2022/09/2022-09-14_17h30_34.png> <strong class="an-zone-tag-top ad-zone-advertising-tag"></strong> <strong class="an-zone-tag-bottom ad-zone-advertising-sub-tag"></strong><p>You can add <code>--always-batch-cond-uncond</code> to try and fix additional memory issues if the previous commands didn't help. There is also an alternative to <code>--medvram</code> that might reduce VRAM usage even more, <code>--lowvram</code>, but we can't attest to whether or not it'll actually work.</p><p>The addition of a user interface is a critical step forward in making these sorts of AI-driven tools accessible to everyone. The possibilities are nearly endless, and even a quick glance at the <a href=#>online communities dedicated to AI art</a> will show you just how powerful the technology is, even while in its infancy. Of course, if you don't have a gaming computer, or you don't want to worry about the setup, you can always use<a href=#> one of the online AI art generators</a>. Just keep in mind that you cannot assume your entries are private.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7qbvWraagnZWge6S7zGhvbGpkbn5wtM6wZK2nXafCr3nSrZibpJVisaqyxa6qoqeeYrmwr8Clo7Jlp57BqXnAZp6uoV2ku27DyKebqK%2BjZA%3D%3D</p></div><div id=links><a href=./joanna-krupa-flashes-generous-boob-gala-html.html>&#171;&nbsp;Joanna Krupa flashes a generous amount of side boob at gala</a>
<a href=./chantal-danielle-biography-age-height-family-net-worth-tellygupshup.html>Chantal Danielle Biography, Age, Height, Family, Net Worth Tellygupshup&nbsp;&#187;</a></div></section><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>